{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-wireless",
   "metadata": {},
   "source": [
    "Now that there are multiple baseline models stored in `models/`, we can proceed to model selection. After the first milestone there will be more models, especially neural networks.  \n",
    "\n",
    "In this notebook I'm going to:\n",
    "1. Evaluate models\n",
    "1. Generate a leaderboard\n",
    "\n",
    "This notebook was run on cluster since there are 2 models kept crashing my MacBook Pro. There's a large space of improvement for resource management of `skorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "united-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passive-antarctica",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:25:13] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import ivpk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-smile",
   "metadata": {},
   "source": [
    "Load models and settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-present",
   "metadata": {},
   "source": [
    "Instead of parsing model file names, I've manually registered the models in a yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "linear-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/model_registration.yaml\", \"r\") as f:\n",
    "    all_models = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-variety",
   "metadata": {},
   "source": [
    "There are 2 types of model objects: sklearn estimator or GridSearchCV. GridSearchCV objects were refit on train+val data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-angola",
   "metadata": {},
   "source": [
    "Note: GridSearchCV train / val metrics should not come from the refit version, use the model.best_score_ for MAE_cv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-superintendent",
   "metadata": {},
   "source": [
    "## VDss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acoustic-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "target = \"VDss\"\n",
    "eval_vdss = ivpk.evalutaion.eval_registered(target, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "piano-cursor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>Pearsonr_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>Pearsonr_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>Pearsonr_test</th>\n",
       "      <th>MAE_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso02_morgan256</th>\n",
       "      <td>1.054101</td>\n",
       "      <td>0.754406</td>\n",
       "      <td>1.129897</td>\n",
       "      <td>0.747520</td>\n",
       "      <td>1.485563</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfreg_morgan256</th>\n",
       "      <td>0.398827</td>\n",
       "      <td>0.974010</td>\n",
       "      <td>1.074936</td>\n",
       "      <td>0.762647</td>\n",
       "      <td>1.431827</td>\n",
       "      <td>0.520605</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_gridsearch</th>\n",
       "      <td>1.073391</td>\n",
       "      <td>0.740603</td>\n",
       "      <td>1.056781</td>\n",
       "      <td>0.788250</td>\n",
       "      <td>1.459111</td>\n",
       "      <td>0.568618</td>\n",
       "      <td>1.163534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfreg_gridsearch</th>\n",
       "      <td>0.384881</td>\n",
       "      <td>0.979040</td>\n",
       "      <td>0.386894</td>\n",
       "      <td>0.981479</td>\n",
       "      <td>1.380789</td>\n",
       "      <td>0.574837</td>\n",
       "      <td>1.068730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_gridsearch</th>\n",
       "      <td>0.616318</td>\n",
       "      <td>0.931349</td>\n",
       "      <td>0.603687</td>\n",
       "      <td>0.938498</td>\n",
       "      <td>1.564690</td>\n",
       "      <td>0.512947</td>\n",
       "      <td>1.167947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_morgan256</th>\n",
       "      <td>0.901812</td>\n",
       "      <td>0.827388</td>\n",
       "      <td>0.925742</td>\n",
       "      <td>0.831301</td>\n",
       "      <td>1.483468</td>\n",
       "      <td>0.538599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_morgan2048</th>\n",
       "      <td>0.883792</td>\n",
       "      <td>0.836584</td>\n",
       "      <td>0.915545</td>\n",
       "      <td>0.842677</td>\n",
       "      <td>1.397092</td>\n",
       "      <td>0.580040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MAE_train  Pearsonr_train   MAE_val  Pearsonr_val  \\\n",
       "lasso02_morgan256   1.054101        0.754406  1.129897      0.747520   \n",
       "rfreg_morgan256     0.398827        0.974010  1.074936      0.762647   \n",
       "lasso_gridsearch    1.073391        0.740603  1.056781      0.788250   \n",
       "rfreg_gridsearch    0.384881        0.979040  0.386894      0.981479   \n",
       "mlp_gridsearch      0.616318        0.931349  0.603687      0.938498   \n",
       "mlp_morgan256       0.901812        0.827388  0.925742      0.831301   \n",
       "mlp_morgan2048      0.883792        0.836584  0.915545      0.842677   \n",
       "\n",
       "                   MAE_test  Pearsonr_test    MAE_cv  \n",
       "lasso02_morgan256  1.485563       0.547800       NaN  \n",
       "rfreg_morgan256    1.431827       0.520605       NaN  \n",
       "lasso_gridsearch   1.459111       0.568618  1.163534  \n",
       "rfreg_gridsearch   1.380789       0.574837  1.068730  \n",
       "mlp_gridsearch     1.564690       0.512947  1.167947  \n",
       "mlp_morgan256      1.483468       0.538599       NaN  \n",
       "mlp_morgan2048     1.397092       0.580040       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vdss = pd.DataFrame([v.evaluation for v in eval_vdss.values()], index=eval_vdss.keys())\n",
    "df_vdss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-fiber",
   "metadata": {},
   "source": [
    "The best model so far is rfreg_gridsearch. Note that on morgan 2048 the MLP regressor actually performed comparable with random forest regressor on morgan 256. For easy computation I'll submit prediction from rfreg_gridsearch, but it would be really interesting to examine the mlp_morgan2048. \n",
    "\n",
    "A bonus task for model interpretation later: consider highlight high importance fingerprint bits on structures.\n",
    "\n",
    "Now let's save the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "veterinary-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vdss.to_csv(\"doc/VDss_leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-portland",
   "metadata": {},
   "source": [
    "## CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "understanding-clearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "target = \"CL\"\n",
    "eval_cl = ivpk.evalutaion.eval_registered(target, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "diagnostic-independence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>Pearsonr_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>Pearsonr_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>Pearsonr_test</th>\n",
       "      <th>MAE_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rfreg_morgan256</th>\n",
       "      <td>0.516649</td>\n",
       "      <td>0.973467</td>\n",
       "      <td>1.394187</td>\n",
       "      <td>0.457802</td>\n",
       "      <td>1.544839</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfreg_gridsearch</th>\n",
       "      <td>0.505391</td>\n",
       "      <td>0.978585</td>\n",
       "      <td>0.504125</td>\n",
       "      <td>0.974885</td>\n",
       "      <td>1.514730</td>\n",
       "      <td>0.271944</td>\n",
       "      <td>1.389895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_gridsearch</th>\n",
       "      <td>1.383372</td>\n",
       "      <td>0.590336</td>\n",
       "      <td>1.371065</td>\n",
       "      <td>0.561811</td>\n",
       "      <td>1.502090</td>\n",
       "      <td>0.276183</td>\n",
       "      <td>1.517285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_morgan256</th>\n",
       "      <td>1.402283</td>\n",
       "      <td>0.564091</td>\n",
       "      <td>1.380383</td>\n",
       "      <td>0.539837</td>\n",
       "      <td>1.489376</td>\n",
       "      <td>0.289302</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MAE_train  Pearsonr_train   MAE_val  Pearsonr_val  MAE_test  \\\n",
       "rfreg_morgan256    0.516649        0.973467  1.394187      0.457802  1.544839   \n",
       "rfreg_gridsearch   0.505391        0.978585  0.504125      0.974885  1.514730   \n",
       "mlp_gridsearch     1.383372        0.590336  1.371065      0.561811  1.502090   \n",
       "mlp_morgan256      1.402283        0.564091  1.380383      0.539837  1.489376   \n",
       "\n",
       "                  Pearsonr_test    MAE_cv  \n",
       "rfreg_morgan256        0.233300       NaN  \n",
       "rfreg_gridsearch       0.271944  1.389895  \n",
       "mlp_gridsearch         0.276183  1.517285  \n",
       "mlp_morgan256          0.289302       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl = pd.DataFrame([v.evaluation for v in eval_cl.values()], index=eval_cl.keys())\n",
    "df_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-unknown",
   "metadata": {},
   "source": [
    "The best one is mlp_morgan256. This model still suffers from high-bias, which implies that properties + fingerprint might not be a good solution to predict CL. Since I didn't run a gridsearchCV for MLP on morgan2048, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "million-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl.to_csv(\"doc/CL_leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-polls",
   "metadata": {},
   "source": [
    "Later we can use [online table converter](https://tableconvert.com/) to convert the leaderboard into markdown for Readme."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bef08d333d8e83100e76baf7a20c87b4db783c5ee109790e906da389d24d1019"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
