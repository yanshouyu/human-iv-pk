{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hydraulic-charter",
   "metadata": {},
   "source": [
    "In this notebook I'll wrap the Pytorch model by `skorch` and fit baseline models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-grade",
   "metadata": {},
   "source": [
    "## Issue: Segmentation fault\n",
    "After several round of experiments I've found that to use `skorch` in local laptop, the model need to be very small otherwise the kernel will restart. If run in command line, the error message was \"zsh: segmentation fault\".  \n",
    "For example, if we use properties + morgan256 as input, the MLP cannot even take hidden dimension as 128 at batch size as low as 4. If set hidden dim to 64, the model can work. There must be a bug.\n",
    "\n",
    "To get baseline MLP, write a script and execute on cluster. Here I'll only use the very small model (nofp) to explore methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "experimental-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from skorch import NeuralNetRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "greater-cover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import ivpk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "curious-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"VDss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "second-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), y_train, (x_val, _), y_val, _, _ = ivpk.data.all_datasets(\n",
    "    target=target, \n",
    "    smiles_func=None, \n",
    "    #fpType=\"morgan\", fpSize=256\n",
    ")\n",
    "x_train, y_train = x_train.astype(np.float32), y_train.reshape(-1, 1).astype(np.float32)\n",
    "x_val, y_val = x_val.astype(np.float32), y_val.reshape(-1, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mechanical-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dl, val_dl = ivpk.data.get_dataloaders(target=target, dests=(\"train\", \"val\"), batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-anniversary",
   "metadata": {},
   "source": [
    "## Basic wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chinese-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "featured-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_reg = ivpk.models.SimpleRegHead(11+256, 512)\n",
    "reg = NeuralNetRegressor(\n",
    "    ivpk.models.SimpleRegHead, \n",
    "    module__in_dim=11, \n",
    "    module__hid_dim=8, \n",
    "    criterion=nn.MSELoss, \n",
    "    optimizer=torch.optim.SGD, \n",
    "    max_epochs=20, \n",
    "    lr=0.01, \n",
    "    batch_size=4, \n",
    "    train_split=None, \n",
    "#    iterator_train=train_dl, \n",
    "#    iterator_valid=val_dl, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cleared-nickname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.5303\u001b[0m  0.1075\n",
      "      2        \u001b[36m2.7825\u001b[0m  0.1086\n",
      "      3        \u001b[36m2.6988\u001b[0m  0.1054\n",
      "      4        \u001b[36m2.6517\u001b[0m  0.1130\n",
      "      5        \u001b[36m2.6180\u001b[0m  0.1216\n",
      "      6        \u001b[36m2.5925\u001b[0m  0.1068\n",
      "      7        \u001b[36m2.5704\u001b[0m  0.1102\n",
      "      8        \u001b[36m2.5492\u001b[0m  0.1297\n",
      "      9        \u001b[36m2.5306\u001b[0m  0.1160\n",
      "     10        \u001b[36m2.5150\u001b[0m  0.1022\n",
      "     11        \u001b[36m2.5013\u001b[0m  0.1092\n",
      "     12        \u001b[36m2.4888\u001b[0m  0.1052\n",
      "     13        \u001b[36m2.4773\u001b[0m  0.1112\n",
      "     14        \u001b[36m2.4668\u001b[0m  0.1126\n",
      "     15        \u001b[36m2.4571\u001b[0m  0.1052\n",
      "     16        \u001b[36m2.4480\u001b[0m  0.1050\n",
      "     17        \u001b[36m2.4395\u001b[0m  0.1049\n",
      "     18        \u001b[36m2.4315\u001b[0m  0.1040\n",
      "     19        \u001b[36m2.4240\u001b[0m  0.1389\n",
      "     20        \u001b[36m2.4168\u001b[0m  0.1317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=SimpleRegHead(\n",
       "    (main): Sequential(\n",
       "      (0): Linear(in_features=11, out_features=8, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=8, out_features=1, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "special-gather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(x_val).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-desert",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-republican",
   "metadata": {},
   "source": [
    "Metrics score callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "catholic-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EpochScoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "accessible-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = EpochScoring(\"neg_mean_absolute_error\", lower_is_better=False, on_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fossil-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = EpochScoring(\"r2\", lower_is_better=False, on_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "electric-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = NeuralNetRegressor(\n",
    "    ivpk.models.SimpleRegHead, \n",
    "    module__in_dim=11, \n",
    "    module__hid_dim=8, \n",
    "    criterion=nn.MSELoss, \n",
    "    optimizer=torch.optim.SGD, \n",
    "    max_epochs=10, \n",
    "    lr=0.01, \n",
    "    batch_size=4, \n",
    "    train_split=None, \n",
    "    callbacks=[r2, mae]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "exempt-summer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    neg_mean_absolute_error      r2    train_loss     dur\n",
      "-------  -------------------------  ------  ------------  ------\n",
      "      1                    \u001b[36m-1.4887\u001b[0m  \u001b[32m0.1974\u001b[0m        \u001b[35m3.6035\u001b[0m  0.1743\n",
      "      2                    \u001b[36m-1.2491\u001b[0m  \u001b[32m0.3775\u001b[0m        \u001b[35m2.7950\u001b[0m  0.1309\n",
      "      3                    \u001b[36m-1.2172\u001b[0m  \u001b[32m0.4058\u001b[0m        \u001b[35m2.6677\u001b[0m  0.1147\n",
      "      4                    \u001b[36m-1.2049\u001b[0m  \u001b[32m0.4145\u001b[0m        \u001b[35m2.6287\u001b[0m  0.1094\n",
      "      5                    \u001b[36m-1.1974\u001b[0m  \u001b[32m0.4198\u001b[0m        \u001b[35m2.6048\u001b[0m  0.1372\n",
      "      6                    \u001b[36m-1.1923\u001b[0m  \u001b[32m0.4238\u001b[0m        \u001b[35m2.5872\u001b[0m  0.1354\n",
      "      7                    \u001b[36m-1.1888\u001b[0m  \u001b[32m0.4269\u001b[0m        \u001b[35m2.5730\u001b[0m  0.1390\n",
      "      8                    \u001b[36m-1.1861\u001b[0m  \u001b[32m0.4296\u001b[0m        \u001b[35m2.5607\u001b[0m  0.1607\n",
      "      9                    \u001b[36m-1.1836\u001b[0m  \u001b[32m0.4322\u001b[0m        \u001b[35m2.5493\u001b[0m  0.1453\n",
      "     10                    \u001b[36m-1.1810\u001b[0m  \u001b[32m0.4348\u001b[0m        \u001b[35m2.5376\u001b[0m  0.1378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=SimpleRegHead(\n",
       "    (main): Sequential(\n",
       "      (0): Linear(in_features=11, out_features=8, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=8, out_features=1, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-screen",
   "metadata": {},
   "source": [
    "Early stopping callback.  \n",
    "Remember early stopping is not compatible with grid search since train-val split in grid search left no validation set of neural network thus it's not possible to monitor the \"valid_loss\". To select a proper model in grid search, we can only try different max epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ancient-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "elementary-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "respected-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = NeuralNetRegressor(\n",
    "    ivpk.models.SimpleRegHead, \n",
    "    module__in_dim=11, \n",
    "    module__hid_dim=8, \n",
    "    criterion=nn.MSELoss, \n",
    "    optimizer=torch.optim.SGD, \n",
    "    max_epochs=50, \n",
    "    lr=0.01, \n",
    "    batch_size=4, \n",
    "#    train_split=None, \n",
    "    callbacks=[r2, earlystop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "destroyed-ensemble",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch      r2    train_loss    valid_loss     dur\n",
      "-------  ------  ------------  ------------  ------\n",
      "      1  \u001b[36m0.1999\u001b[0m        \u001b[32m3.6021\u001b[0m        \u001b[35m3.0378\u001b[0m  0.1219\n",
      "      2  \u001b[36m0.3342\u001b[0m        \u001b[32m2.9975\u001b[0m        \u001b[35m2.6723\u001b[0m  0.1274\n",
      "      3  \u001b[36m0.3554\u001b[0m        \u001b[32m2.9022\u001b[0m        \u001b[35m2.5569\u001b[0m  0.1130\n",
      "      4  \u001b[36m0.3667\u001b[0m        \u001b[32m2.8510\u001b[0m        \u001b[35m2.4924\u001b[0m  0.1137\n",
      "      5  \u001b[36m0.3772\u001b[0m        \u001b[32m2.8040\u001b[0m        \u001b[35m2.4422\u001b[0m  0.1032\n",
      "      6  \u001b[36m0.3892\u001b[0m        \u001b[32m2.7497\u001b[0m        \u001b[35m2.3896\u001b[0m  0.1019\n",
      "      7  \u001b[36m0.4021\u001b[0m        \u001b[32m2.6918\u001b[0m        \u001b[35m2.3579\u001b[0m  0.1015\n",
      "      8  \u001b[36m0.4108\u001b[0m        \u001b[32m2.6528\u001b[0m        \u001b[35m2.3482\u001b[0m  0.1021\n",
      "      9  \u001b[36m0.4163\u001b[0m        \u001b[32m2.6278\u001b[0m        \u001b[35m2.3432\u001b[0m  0.1010\n",
      "     10  \u001b[36m0.4208\u001b[0m        \u001b[32m2.6076\u001b[0m        \u001b[35m2.3387\u001b[0m  0.0993\n",
      "     11  \u001b[36m0.4249\u001b[0m        \u001b[32m2.5893\u001b[0m        \u001b[35m2.3341\u001b[0m  0.1005\n",
      "     12  \u001b[36m0.4287\u001b[0m        \u001b[32m2.5722\u001b[0m        \u001b[35m2.3296\u001b[0m  0.1010\n",
      "     13  \u001b[36m0.4322\u001b[0m        \u001b[32m2.5565\u001b[0m        \u001b[35m2.3253\u001b[0m  0.1002\n",
      "     14  \u001b[36m0.4354\u001b[0m        \u001b[32m2.5418\u001b[0m        \u001b[35m2.3215\u001b[0m  0.1017\n",
      "     15  \u001b[36m0.4385\u001b[0m        \u001b[32m2.5281\u001b[0m        \u001b[35m2.3184\u001b[0m  0.1009\n",
      "     16  \u001b[36m0.4414\u001b[0m        \u001b[32m2.5150\u001b[0m        \u001b[35m2.3158\u001b[0m  0.0999\n",
      "     17  \u001b[36m0.4442\u001b[0m        \u001b[32m2.5024\u001b[0m        \u001b[35m2.3138\u001b[0m  0.1003\n",
      "     18  \u001b[36m0.4469\u001b[0m        \u001b[32m2.4900\u001b[0m        \u001b[35m2.3122\u001b[0m  0.1002\n",
      "     19  \u001b[36m0.4496\u001b[0m        \u001b[32m2.4778\u001b[0m        \u001b[35m2.3108\u001b[0m  0.1015\n",
      "     20  \u001b[36m0.4523\u001b[0m        \u001b[32m2.4657\u001b[0m        \u001b[35m2.3097\u001b[0m  0.0990\n",
      "     21  \u001b[36m0.4550\u001b[0m        \u001b[32m2.4537\u001b[0m        \u001b[35m2.3086\u001b[0m  0.1263\n",
      "     22  \u001b[36m0.4576\u001b[0m        \u001b[32m2.4419\u001b[0m        \u001b[35m2.3075\u001b[0m  0.0995\n",
      "     23  \u001b[36m0.4601\u001b[0m        \u001b[32m2.4304\u001b[0m        \u001b[35m2.3062\u001b[0m  0.1011\n",
      "     24  \u001b[36m0.4625\u001b[0m        \u001b[32m2.4197\u001b[0m        \u001b[35m2.3047\u001b[0m  0.0993\n",
      "     25  \u001b[36m0.4647\u001b[0m        \u001b[32m2.4099\u001b[0m        \u001b[35m2.3031\u001b[0m  0.0988\n",
      "     26  \u001b[36m0.4666\u001b[0m        \u001b[32m2.4012\u001b[0m        \u001b[35m2.3015\u001b[0m  0.0978\n",
      "     27  \u001b[36m0.4684\u001b[0m        \u001b[32m2.3935\u001b[0m        \u001b[35m2.3001\u001b[0m  0.0993\n",
      "     28  \u001b[36m0.4699\u001b[0m        \u001b[32m2.3865\u001b[0m        \u001b[35m2.2990\u001b[0m  0.1031\n",
      "     29  \u001b[36m0.4713\u001b[0m        \u001b[32m2.3803\u001b[0m        \u001b[35m2.2981\u001b[0m  0.0973\n",
      "     30  \u001b[36m0.4725\u001b[0m        \u001b[32m2.3747\u001b[0m        \u001b[35m2.2974\u001b[0m  0.0981\n",
      "     31  \u001b[36m0.4736\u001b[0m        \u001b[32m2.3698\u001b[0m        \u001b[35m2.2970\u001b[0m  0.0992\n",
      "     32  \u001b[36m0.4746\u001b[0m        \u001b[32m2.3654\u001b[0m        \u001b[35m2.2968\u001b[0m  0.0984\n",
      "Stopping since valid_loss has not improved in the last 1 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=SimpleRegHead(\n",
       "    (main): Sequential(\n",
       "      (0): Linear(in_features=11, out_features=8, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=8, out_features=1, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "conservative-assessment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(x_val).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-poison",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "straight-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "failing-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = NeuralNetRegressor(\n",
    "    ivpk.models.SimpleRegHead, \n",
    "    module__in_dim=11, \n",
    "    module__hid_dim=8, \n",
    "    criterion=nn.MSELoss, \n",
    "    optimizer=torch.optim.SGD, \n",
    "    max_epochs=50, \n",
    "    lr=0.01, \n",
    "    batch_size=4, \n",
    "    train_split=None, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "center-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample param grid for efficiency\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.005],\n",
    "    'module__hid_dim': [4, 8],\n",
    "    'module__dropout': [0, 0.2],\n",
    "    'max_epochs': [2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "incomplete-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(reg, param_grid, refit=True, cv=3, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "valued-bumper",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.3928\u001b[0m  0.0791\n",
      "      2        \u001b[36m4.0993\u001b[0m  0.0753\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.2986\u001b[0m  0.0737\n",
      "      2        \u001b[36m4.0903\u001b[0m  0.0751\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.3791\u001b[0m  0.0766\n",
      "      2        \u001b[36m4.1695\u001b[0m  0.0756\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4790\u001b[0m  0.0904\n",
      "      2        \u001b[36m4.2622\u001b[0m  0.0891\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1695\u001b[0m  0.0826\n",
      "      2        \u001b[36m3.8662\u001b[0m  0.0972\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4571\u001b[0m  0.0934\n",
      "      2        \u001b[36m4.1761\u001b[0m  0.0882\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.5844\u001b[0m  0.0775\n",
      "      2        \u001b[36m4.5220\u001b[0m  0.0809\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4218\u001b[0m  0.0999\n",
      "      2        \u001b[36m4.3459\u001b[0m  0.0981\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4351\u001b[0m  0.0910\n",
      "      2        \u001b[36m4.3004\u001b[0m  0.0904\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.7822\u001b[0m  0.1069\n",
      "      2        \u001b[36m4.4827\u001b[0m  0.1048\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4979\u001b[0m  0.0751\n",
      "      2        \u001b[36m4.3800\u001b[0m  0.0763\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.3011\u001b[0m  0.0715\n",
      "      2        \u001b[36m3.9914\u001b[0m  0.0772\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.5860\u001b[0m  0.0858\n",
      "      2        \u001b[36m4.3272\u001b[0m  0.0903\n",
      "      3        \u001b[36m4.0607\u001b[0m  0.0814\n",
      "      4        \u001b[36m3.7888\u001b[0m  0.0878\n",
      "      5        \u001b[36m3.5577\u001b[0m  0.0985\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.0890\u001b[0m  0.0894\n",
      "      2        \u001b[36m3.7512\u001b[0m  0.0901\n",
      "      3        \u001b[36m3.5611\u001b[0m  0.0908\n",
      "      4        \u001b[36m3.4284\u001b[0m  0.0772\n",
      "      5        \u001b[36m3.3073\u001b[0m  0.0789\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4479\u001b[0m  0.0817\n",
      "      2        \u001b[36m4.2467\u001b[0m  0.0902\n",
      "      3        \u001b[36m4.0430\u001b[0m  0.0943\n",
      "      4        \u001b[36m3.8436\u001b[0m  0.0928\n",
      "      5        \u001b[36m3.6557\u001b[0m  0.0838\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.2560\u001b[0m  0.0818\n",
      "      2        \u001b[36m3.9392\u001b[0m  0.0770\n",
      "      3        \u001b[36m3.6966\u001b[0m  0.0766\n",
      "      4        \u001b[36m3.5286\u001b[0m  0.0938\n",
      "      5        \u001b[36m3.3980\u001b[0m  0.0914\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.3479\u001b[0m  0.0861\n",
      "      2        \u001b[36m4.0932\u001b[0m  0.0786\n",
      "      3        \u001b[36m3.8324\u001b[0m  0.0794\n",
      "      4        \u001b[36m3.5853\u001b[0m  0.0780\n",
      "      5        \u001b[36m3.3869\u001b[0m  0.0765\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.9362\u001b[0m  0.0801\n",
      "      2        \u001b[36m3.6531\u001b[0m  0.0859\n",
      "      3        \u001b[36m3.4264\u001b[0m  0.0953\n",
      "      4        \u001b[36m3.2691\u001b[0m  0.1219\n",
      "      5        \u001b[36m3.1621\u001b[0m  0.0934\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.6762\u001b[0m  0.0881\n",
      "      2        \u001b[36m4.4708\u001b[0m  0.0824\n",
      "      3        \u001b[36m4.3212\u001b[0m  0.0813\n",
      "      4        \u001b[36m4.1975\u001b[0m  0.0927\n",
      "      5        \u001b[36m4.0052\u001b[0m  0.1044\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4872\u001b[0m  0.1068\n",
      "      2        \u001b[36m4.2172\u001b[0m  0.0926\n",
      "      3        \u001b[36m4.0426\u001b[0m  0.0868\n",
      "      4        \u001b[36m3.9075\u001b[0m  0.0810\n",
      "      5        \u001b[36m3.7088\u001b[0m  0.0800\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.5360\u001b[0m  0.0764\n",
      "      2        \u001b[36m4.3918\u001b[0m  0.0858\n",
      "      3        \u001b[36m4.2547\u001b[0m  0.0904\n",
      "      4        \u001b[36m4.0749\u001b[0m  0.0875\n",
      "      5        \u001b[36m3.8852\u001b[0m  0.0870\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.9129\u001b[0m  0.0746\n",
      "      2        \u001b[36m3.7026\u001b[0m  0.0783\n",
      "      3        \u001b[36m3.6259\u001b[0m  0.0839\n",
      "      4        \u001b[36m3.4981\u001b[0m  0.1194\n",
      "      5        \u001b[36m3.4335\u001b[0m  0.1101\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.5077\u001b[0m  0.0954\n",
      "      2        \u001b[36m4.2049\u001b[0m  0.0958\n",
      "      3        \u001b[36m4.0063\u001b[0m  0.0943\n",
      "      4        \u001b[36m3.8041\u001b[0m  0.0909\n",
      "      5        \u001b[36m3.6859\u001b[0m  0.0952\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1775\u001b[0m  0.0898\n",
      "      2        \u001b[36m3.9024\u001b[0m  0.0851\n",
      "      3        \u001b[36m3.6715\u001b[0m  0.0829\n",
      "      4        \u001b[36m3.5504\u001b[0m  0.0909\n",
      "      5        \u001b[36m3.3893\u001b[0m  0.0829\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1299\u001b[0m  0.0723\n",
      "      2        \u001b[36m3.4195\u001b[0m  0.0798\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.3373\u001b[0m  0.0800\n",
      "      2        \u001b[36m3.7873\u001b[0m  0.0821\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1808\u001b[0m  0.0816\n",
      "      2        \u001b[36m3.4823\u001b[0m  0.0745\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.4987\u001b[0m  0.0713\n",
      "      2        \u001b[36m2.9834\u001b[0m  0.0789\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1702\u001b[0m  0.0708\n",
      "      2        \u001b[36m3.3990\u001b[0m  0.0747\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8337\u001b[0m  0.0930\n",
      "      2        \u001b[36m3.2445\u001b[0m  0.1002\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8116\u001b[0m  0.1015\n",
      "      2        \u001b[36m3.1818\u001b[0m  0.0859\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.0853\u001b[0m  0.0781\n",
      "      2        \u001b[36m3.6107\u001b[0m  0.0858\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8336\u001b[0m  0.0794\n",
      "      2        \u001b[36m3.2800\u001b[0m  0.0857\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1552\u001b[0m  0.0797\n",
      "      2        \u001b[36m3.4333\u001b[0m  0.0869\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1851\u001b[0m  0.0905\n",
      "      2        \u001b[36m3.7344\u001b[0m  0.1033\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.0545\u001b[0m  0.1443\n",
      "      2        \u001b[36m3.3337\u001b[0m  0.1111\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.2649\u001b[0m  0.0876\n",
      "      2        \u001b[36m3.3127\u001b[0m  0.0927\n",
      "      3        \u001b[36m2.9171\u001b[0m  0.0911\n",
      "      4        \u001b[36m2.7523\u001b[0m  0.0920\n",
      "      5        \u001b[36m2.6946\u001b[0m  0.0868\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4123\u001b[0m  0.0815\n",
      "      2        \u001b[36m3.9675\u001b[0m  0.0749\n",
      "      3        \u001b[36m3.3266\u001b[0m  0.0852\n",
      "      4        \u001b[36m2.9268\u001b[0m  0.0824\n",
      "      5        \u001b[36m2.7166\u001b[0m  0.0773\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4732\u001b[0m  0.0741\n",
      "      2        \u001b[36m3.8505\u001b[0m  0.0794\n",
      "      3        \u001b[36m3.3883\u001b[0m  0.0807\n",
      "      4        \u001b[36m3.1178\u001b[0m  0.0846\n",
      "      5        \u001b[36m2.9735\u001b[0m  0.0833\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8017\u001b[0m  0.0733\n",
      "      2        \u001b[36m3.0168\u001b[0m  0.0771\n",
      "      3        \u001b[36m2.8004\u001b[0m  0.0784\n",
      "      4        \u001b[36m2.7236\u001b[0m  0.0769\n",
      "      5        \u001b[36m2.6961\u001b[0m  0.0756\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.0811\u001b[0m  0.0751\n",
      "      2        \u001b[36m3.4368\u001b[0m  0.0760\n",
      "      3        \u001b[36m3.0401\u001b[0m  0.0769\n",
      "      4        \u001b[36m2.7880\u001b[0m  0.0781\n",
      "      5        \u001b[36m2.6581\u001b[0m  0.0770\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8973\u001b[0m  0.0722\n",
      "      2        \u001b[36m3.1572\u001b[0m  0.0779\n",
      "      3        \u001b[36m2.9187\u001b[0m  0.0784\n",
      "      4        \u001b[36m2.7861\u001b[0m  0.1013\n",
      "      5        \u001b[36m2.7199\u001b[0m  0.1002\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.2291\u001b[0m  0.0947\n",
      "      2        \u001b[36m3.7952\u001b[0m  0.0962\n",
      "      3        \u001b[36m3.4235\u001b[0m  0.0947\n",
      "      4        \u001b[36m3.2637\u001b[0m  0.0920\n",
      "      5        \u001b[36m3.1588\u001b[0m  0.0952\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1610\u001b[0m  0.0961\n",
      "      2        \u001b[36m3.5906\u001b[0m  0.0970\n",
      "      3        \u001b[36m3.3162\u001b[0m  0.0976\n",
      "      4        \u001b[36m3.1149\u001b[0m  0.1034\n",
      "      5        \u001b[36m3.0500\u001b[0m  0.0936\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8811\u001b[0m  0.0815\n",
      "      2        \u001b[36m3.4291\u001b[0m  0.0830\n",
      "      3        \u001b[36m3.2448\u001b[0m  0.0851\n",
      "      4        \u001b[36m3.1053\u001b[0m  0.0873\n",
      "      5        \u001b[36m2.9733\u001b[0m  0.0827\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.3380\u001b[0m  0.0846\n",
      "      2        \u001b[36m3.6759\u001b[0m  0.0861\n",
      "      3        \u001b[36m3.1118\u001b[0m  0.0948\n",
      "      4        \u001b[36m3.0127\u001b[0m  0.1250\n",
      "      5        \u001b[36m2.8767\u001b[0m  0.0919\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.9059\u001b[0m  0.0884\n",
      "      2        \u001b[36m3.1138\u001b[0m  0.0829\n",
      "      3        \u001b[36m2.9159\u001b[0m  0.0802\n",
      "      4        \u001b[36m2.8263\u001b[0m  0.0819\n",
      "      5        \u001b[36m2.7498\u001b[0m  0.0836\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8243\u001b[0m  0.0772\n",
      "      2        \u001b[36m3.3865\u001b[0m  0.0813\n",
      "      3        \u001b[36m3.1083\u001b[0m  0.0802\n",
      "      4        \u001b[36m3.0727\u001b[0m  0.0816\n",
      "      5        \u001b[36m2.8608\u001b[0m  0.0822\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.7945\u001b[0m  0.1096\n",
      "      2        \u001b[36m2.9814\u001b[0m  0.1065\n",
      "      3        \u001b[36m2.7544\u001b[0m  0.1079\n",
      "      4        \u001b[36m2.6985\u001b[0m  0.1074\n",
      "      5        \u001b[36m2.6739\u001b[0m  0.1082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<class 'skorch.regressor.NeuralNetRegressor'>[uninitialized](\n",
       "  module=<class 'ivpk.models.SimpleRegHead'>,\n",
       "  module__hid_dim=8,\n",
       "  module__in_dim=11,\n",
       "),\n",
       "             param_grid={'lr': [0.001, 0.005], 'max_epochs': [2, 5],\n",
       "                         'module__dropout': [0, 0.2],\n",
       "                         'module__hid_dim': [4, 8]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afraid-visitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=SimpleRegHead(\n",
       "    (main): Sequential(\n",
       "      (0): Linear(in_features=11, out_features=8, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Dropout(p=0, inplace=False)\n",
       "      (3): Linear(in_features=8, out_features=1, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "developmental-karma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.005, 'max_epochs': 5, 'module__dropout': 0, 'module__hid_dim': 8}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "weekly-casino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.21109934647878"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "activated-computer",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batches': [{'train_loss': 7.843193054199219, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.9014673233032227, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.8766525983810425, 'train_batch_size': 4},\n",
       "  {'train_loss': 11.758108139038086, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.4747419357299805, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.248571395874023, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.872438430786133, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.09492123872041702, 'train_batch_size': 4},\n",
       "  {'train_loss': 8.943922996520996, 'train_batch_size': 4},\n",
       "  {'train_loss': 8.077860832214355, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.599372386932373, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.5913069248199463, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.7337045669555664, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.423847675323486, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.3838701248168945, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.449618339538574, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.041208744049072, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.366849422454834, 'train_batch_size': 4},\n",
       "  {'train_loss': 11.987295150756836, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.24084734916687, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.024573564529419, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.090505838394165, 'train_batch_size': 4},\n",
       "  {'train_loss': 8.6761474609375, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.884397983551025, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.5404503345489502, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.7912967205047607, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.927350997924805, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.986647844314575, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.8976078033447266, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.500633716583252, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.23691463470459, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.094061851501465, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.203190803527832, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.7044529914855957, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.4341583251953125, 'train_batch_size': 4},\n",
       "  {'train_loss': 15.419814109802246, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.5048508644104, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.114735722541809, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.09439755231142044, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.410345554351807, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.4582841396331787, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.0113935470581055, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.700584650039673, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.41000452637672424, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.15649938583374, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.300421953201294, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.230885982513428, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.4995923042297363, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.42556619644165, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.4917075634002686, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.14302396774292, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.984455108642578, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.9958133697509766, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.9305300116539001, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.9184365272521973, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.8402130603790283, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.254612445831299, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.075913429260254, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.040431022644043, 'train_batch_size': 4},\n",
       "  {'train_loss': 7.487072467803955, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.8006067276000977, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.137956619262695, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.264430522918701, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.52424430847168, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.8878878355026245, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.3529694080352783, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.8938164710998535, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.79620361328125, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.5762503743171692, 'train_batch_size': 4},\n",
       "  {'train_loss': 7.382156848907471, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.0106768608093262, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.2748467922210693, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.264211654663086, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.29702502489089966, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.4008561372756958, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.059139251708984, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.0882649421691895, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.296676158905029, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.9584790468215942, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.1673847436904907, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.439969539642334, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.8618597984313965, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.063221454620361, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.6193957328796387, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.7166266441345215, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.5309743881225586, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.785504102706909, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.644882202148438, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.421592712402344, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.096038818359375, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.1396284103393555, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.116082668304443, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.0700697898864746, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.1668853759765625, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.0847396850585938, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.636559963226318, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.172924041748047, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.605952501296997, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.737715482711792, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.36821448802948, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.536848783493042, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.6400319337844849, 'train_batch_size': 4},\n",
       "  {'train_loss': 10.646337509155273, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.9856858253479, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.5231204032897949, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.3269755840301514, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.652100086212158, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.8624106049537659, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.1226128339767456, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.4167492389678955, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.1682039499282837, 'train_batch_size': 4},\n",
       "  {'train_loss': 8.958902359008789, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.552873611450195, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.652771472930908, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.55342435836792, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.108840227127075, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.496087074279785, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.3357720375061035, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.7631072998046875, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.8270779252052307, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.2276597023010254, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.8677734732627869, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.5489489436149597, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.280784606933594, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.277165412902832, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.6801509857177734, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.928123950958252, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.3974252939224243, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.785345554351807, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.826026678085327, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.3714449405670166, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.847743988037109, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.0050691366195679, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.248193740844727, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.3172825574874878, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.6981867551803589, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.6468634605407715, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.7028995752334595, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.2117838859558105, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.9400835037231445, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.921258449554443, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.010799884796143, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.151984691619873, 'train_batch_size': 4},\n",
       "  {'train_loss': 23.161508560180664, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.9652903079986572, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.2496156692504883, 'train_batch_size': 4},\n",
       "  {'train_loss': 11.218506813049316, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.625738799571991, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.9968276023864746, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.028813123703003, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.511600971221924, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.127965927124023, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.791475296020508, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.865047931671143, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.5708578824996948, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.9489552974700928, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.13471794128418, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.7199480533599854, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.4105091094970703, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.996457815170288, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.858904242515564, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.4516282081604, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.821685552597046, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.608537197113037, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.7140194177627563, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.964226722717285, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.114513874053955, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.2244648933410645, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.8706433773040771, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.8997273445129395, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.940209150314331, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.543600559234619, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.490660667419434, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.177571296691895, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.0237178802490234, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.763611793518066, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.0177834033966064, 'train_batch_size': 4},\n",
       "  {'train_loss': 6.946306228637695, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.0746781826019287, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.5976135730743408, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.375154972076416, 'train_batch_size': 4},\n",
       "  {'train_loss': 8.690052032470703, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.6876766681671143, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.1061376333236694, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.6300532817840576, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.507383346557617, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.9043391346931458, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.332171678543091, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.31842756271362305, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.0358731746673584, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.3699543476104736, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.6168456077575684, 'train_batch_size': 4},\n",
       "  {'train_loss': 8.484560012817383, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.3651995658874512, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.3376948833465576, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.219882011413574, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.951263904571533, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.83228600025177, 'train_batch_size': 4},\n",
       "  {'train_loss': 3.1389827728271484, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.3238525390625, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.6222251653671265, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.102022171020508, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.097557067871094, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.1187355518341064, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.772882461547852, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.7407302856445312, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.7471360564231873, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.1512722969055176, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.25872802734375, 'train_batch_size': 4},\n",
       "  {'train_loss': 10.071968078613281, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.1080265045166016, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.482504844665527, 'train_batch_size': 4},\n",
       "  {'train_loss': 9.376260757446289, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.676090717315674, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.0948076248168945, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.9175788164138794, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.12370432913303375, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.809814929962158, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.6561027765274048, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.4374760389328003, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.028553009033203, 'train_batch_size': 4},\n",
       "  {'train_loss': 5.304931640625, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.0813632011413574, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.3872125148773193, 'train_batch_size': 4},\n",
       "  {'train_loss': 2.2451210021972656, 'train_batch_size': 4},\n",
       "  {'train_loss': 1.1714451313018799, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.7441446781158447, 'train_batch_size': 4},\n",
       "  {'train_loss': 4.323754787445068, 'train_batch_size': 4},\n",
       "  {'train_loss': 0.41424763202667236, 'train_batch_size': 2}],\n",
       " 'epoch': 1,\n",
       " 'train_batch_count': 229,\n",
       " 'dur': 0.10957598686218262,\n",
       " 'train_loss': 3.7945410699239184,\n",
       " 'train_loss_best': True}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.history_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-vegetable",
   "metadata": {},
   "source": [
    "## GridSearchCV on cluster\n",
    "\n",
    "The parameters for GridSearchCV on cluster in YAML:\n",
    "```\n",
    "param_grid:\n",
    "  module__hid_dim: [64, 128, 256, 512]\n",
    "  module__dropout: [0, 0.1, 0.2, 0.3, 0.5]\n",
    "  lr: [0.001, 0.01, 0.05]\n",
    "  max_epochs: [20, 50, 100, 200]\n",
    "```\n",
    "\n",
    "The `GridSearchCV`-wrapped-`NeuralNetRegressor`-wrapped-MLP is stored in `models/GridSearchCV` with other GridSearchCV objects.\n",
    "\n",
    "The results were a little worse than random forest regressor. I even tried to use morgan2048 as input. Compared with properties + morgan256, properties + morgan2048 is better for MLP, but still slightly worse than random forest regressor. Here we only discussed the train+val set, leaving test set unseen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-friendship",
   "metadata": {},
   "source": [
    "## Finalize MLP\n",
    "\n",
    "In this part I'm going to use the best MLP hyperparameters from GridSearchCV to train MLP on the train-val split. Note that we can set same train-val split as our split in `ivpk.data.all_datasets` by setting the same random_state in `skorch.dataset.CVSplit()`.\n",
    "\n",
    "The result MLP will be registered for later evaluation along with other ML models.\n",
    "\n",
    "Due to the skorch memory issue, the training will be performed on cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-causing",
   "metadata": {},
   "source": [
    "#### VDss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outside-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/GridSearchCV/VDss_MLP_gridsearch.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blocked-retention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=SimpleRegHead(\n",
       "    (main): Sequential(\n",
       "      (0): Linear(in_features=267, out_features=64, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "operating-combination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imposed-communication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.05, 'max_epochs': 50, 'module__dropout': 0.3, 'module__hid_dim': 64}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-recall",
   "metadata": {},
   "source": [
    "#### CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "after-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/GridSearchCV/CL_MLP_gridsearch.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "physical-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=SimpleRegHead(\n",
       "    (main): Sequential(\n",
       "      (0): Linear(in_features=267, out_features=512, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "contrary-evening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "further-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.001,\n",
       " 'max_epochs': 200,\n",
       " 'module__dropout': 0.3,\n",
       " 'module__hid_dim': 512}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-personality",
   "metadata": {},
   "source": [
    "Next I'll check all saved models to create a leaderboard and report results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
